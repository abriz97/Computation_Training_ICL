---
title: "Computational Training: running fastR"
format: revealjs
---

## Great R resources

::: nonincremental
In general:

1.  [Advanced R](https://adv-r.hadley.nz/)
2.  [R for Data Science](https://r4ds.hadley.nz/)
3.  [RStudio Cheatsheets](https://www.rstudio.com/resources/cheatsheets/)
4.  [Useful R packages](https://support.posit.co/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages)

Covering this session's topics

5.  [data.table](https://rdatatable.gitlab.io/data.table/)
6.  [parallel](https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html#the-parallel-package)
:::

## What is "fast code"?

1.  ‚úèÔ∏è **Easy to write**\
    familiarity with code editor, libraries

2.  üí° **Easy to understand**\
    structured, with consistent variable names, commented.

3.  üîß **Easy to debug**\
    clear naming, DRY, tests.

4.  üèéÔ∏è **Easy to run**\
    (profiling, C++, using "optimized" code).

## Variable naming

::: r-stack
![](../figures/MagrittePipe.jpg){.fragment height="250" fig-align="center"}

![](../figures/catcat.png){.fragment height="250" fig-align="center"}
:::

. . .

names should be consistent, descriptive, lower case, readable.

. . .

For which snippet is it easier to guess the context?

::: columns
::: {.column width="50%"}
```{r}
tmp <-  10
tmp1 <- tmp * 24
```
:::

::: {.column width="50%"}
```{r}
cases_per_hour <- 10
cases_per_day <- cases_per_hour * 24
```
:::
:::

::: footer
[Dealing with the 2nd hardest thing in computer science (Patil)](https://indrajeetpatil.github.io/second-hardest-cs-thing/#/dealing-with-the-second-hardest-thing-in-computer-science)
:::

## Embrace functional programming I

*Functions are first-class citizens in R*

::: columns
::: {.column width="57%"}
-   can be passed as arguments
-   can be returned from other functions
-   can be assigned to variables
-   and more...
:::

::: {.column .fragment width="41%"}
```{r functional-programming-i }
#| filename: "first-class-citizenship.R"
#| warning: false

f <- function(x){x^2}

lapply(1:10, f)

generator <- function(n=2){
    function(x){x^n}
}
cube <- generator(3)

list(one_function = f)
```
:::
:::

## Embrace functional programming II

*Rethink for, while loops; "apply" instead*

. . .

> "To become significantly more reliable, code must become more transparent. In particular, nested conditions and loops must be viewed with great suspicion. Complicated control flows confuse programmers. Messy code often hides bugs."
>
> --- Bjarne Stroustrup

::: footer
[Advanced R, Funtional Programming (Wickham)](https://adv-r.hadley.nz/functionals.html)
:::

. . .

::: {style="text-align: right;"}
**...but why?**
:::

## 

Say you want to extract the $R^2$ from three linear models with different predictors (or formulae).

```{r }
#| filename: "formulae.R"
#| warning: false
formulae <- c(
    Sepal.Length ~ Sepal.Width,
    Sepal.Length ~ Petal.Length,
    Sepal.Length ~ Species
)
```

. . .

::: columns
::: {.column .fragment width="50%"}
```{r for-loop}
#| filename: "bad way"
#| warning: false
lm_results2 <- c()

for (formula in formulae) {
    fit <- lm(formula, data = iris)
    r2 <- summary(fit)$r.squared
    lm_results2 <- c(lm_results2, r2)
}
```
:::

::: {.column .fragment width="50%"}
```{r }
#| filename: "good way"
#| warning: false
extract_r2 <- function(formula) {
    fit <- lm(formula, data = iris)
    r2 <- summary(fit)$r.squared
    return(r2)
}

lm_results <- sapply(formulae, extract_r2)
```
:::
:::

. . .

::: {style="text-align: center;"}
What's the difference?
:::

. . .

```{r}
#| filename: "side effects"
#| warning: false
exists("fit")
```

::: footer
[Advanced R, Functional Programming (Wickham)](https://adv-r.hadley.nz/fp.html)
:::

::: notes
-   For loops may still be prefered (or the only choice), when the order of execution is important, and different runs may affect each other.
:::

## The `parallel` package

You can imagine wanting to run each of the apply/for loop iterations in `parallel`.

::: notes
especially if iterations are independent and computationally expensive. Two quick sentences on the two different approaches.
:::

::: columns
::: {.column .fragment width="50%"}
```{r socket}
#| filename: "sockets (not on Windows)"
#| warning: false

library(parallel)
f <- function(i) {
    lme4::lmer(
        Petal.Width ~ . - Species + (1 | Species),
        data = iris)
}

system.time(save1 <- lapply(1:100, f))
##    user  system elapsed
##   2.048   0.019   2.084
system.time(save2 <- mclapply(1:100, f))
##    user  system elapsed
##   1.295   0.150   1.471
```
:::

::: {.column .fragment width="50%"}
```{r }
#| filename: "forking"
#| warning: false

num_cores <- detectCores()
cl <- makeCluster(num_cores)
system.time(save3 <- parLapply(cl, 1:100, f))
#    user  system elapsed 
#   0.198   0.044   1.032 
stopCluster(cl)
```

-   requires further attention
:::
:::

::: footer
[Parallel computing in R](https://dept.stat.lsa.umich.edu/~jerrick/courses/stat701/notes/parallel.html#the-parallel-package)
:::

## Introduction to [data.table](https://rdatatable.gitlab.io/data.table/)

-   `data.table` is a package that extends the data.frame class.
-   (Quicker) alternative to `dplyr` for large datasets.
-   [cheatsheet](https://rstudio.github.io/cheatsheets/datatable.pdf)

## all you need to know {auto-animate=true auto-animate-easing="ease-in-out"}

::: {data-id="dt" auto-animate-delay="0" style="text-align: center; font-size: 100px;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::

-   use the data.table called `dt` ...
-   subset it on the rows specified by [i]{style="color:blue;"}...
-   and manipulate columns with [j]{style="color:red;"}...
-   grouped according to [by]{style="color:green;"}.

. . .

```{r}
#| eval: true
library(data.table)
iris_dt <- as.data.table(iris)
```

## `iris` summaries {auto-animate=true auto-animate-easing="ease-in-out"} 

#### Subsetting and Summarizing 

::: top-right
::: {data-id="dt" auto-animate-delay="0" style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

::: columns
::: {.column .fragment width="50%"}
-   Say we want to calculate [the mean sepal length]{style="color:red;"} for the [setosa species]{style="color:blue;"}...
:::

::: {.column .fragment width="50%"}
```{r}
#| eval: true
iris_dt[Species == "setosa", mean(Sepal.Length)]
```
:::
:::

#### Grouping and Aggregating

::: top-right
::: {style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

::: columns
::: {.column .fragment width="50%"}
-   Now we want to [repeat the above]{style="color:red;"} for [every species]{style="color:green;"}, in one command.
:::

::: {.column .fragment width="50%"}
```{r}
#| eval: true
iris_dt[, mean(Sepal.Length), by=Species]
```
:::
:::

## `iris` summaries (`.VARS`)

::: top-right
::: {style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

#### Counting entries (`.N`)

::: columns
::: {.column .fragment width="50%"}
-   Count the total [number of observations]{style="color:red;"} per [species]{style="color:green;"}, with [sepal length \> 5]{style="color:blue;"}.
:::

::: {.column .fragment width="50%"}
```{r}
#| eval: true
iris_dt[Sepal.Length>5, .N, by=Species]
```
:::
:::

#### Print 1st entry of each group (`.SD`)

::: top-right
::: {style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

::: columns
::: {.column .fragment width="50%"}
-   Print the [first entry]{style="color:red;"} of each [group (species)]{style="color:green;"}.
:::

::: {.column .fragment width="50%"}
```{r}
#| eval: true
iris_dt[, .SD[1], by=Species]
```
:::

::: footer
`?.I` for documentation on data.table's special symbols.
:::
:::

## Modifying the `dt` (in place)

::: top-right
::: {style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

You will need a walrus (operator):

::: {.columns}

::: {.column width="50%" }

::: {style="text-align: center; font-size: 100px;"}
`:=` 
:::

::: {.nonincremental .smaller .fragment}
- used in <span style="color:red;"> j </span> 
- `name := vector` to act on a single column.
- `(names) := list of vectors` to act on multiple columns.
:::

:::

::: {.column width="50%"}
![](../figures/walrus.jpeg){height="300" fig-align="center"}
:::

:::



## Modifying the `dt` (in place)


#### Define a new column

::: columns
::: {.column .fragment width="50%"}
-   Say you want species names to sound more Italian.
:::

::: {.column .fragment width="50%"}
```{r}
#| eval: true
iris_dt[, Species_ita := paste0(
    Species, 'ino'
), by=Species]
iris_dt[, unique(Species_ita)]
```
:::
:::

#### Modify existing column

::: top-right
::: {style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

::: columns
::: {.column .fragment width="50%"}
-   The "aino" ending does not sound right, let's remove the "a".
:::

::: {.column .fragment width="50%"}
```{r}
#| eval: true
iris_dt[, Species_ita := gsub(
    "aino","ino",
    Species_ita
), by=Species_ita]
iris_dt[, unique(Species_ita)]
```
:::
:::

## Acting on multiple columns

::: top-right
::: {style="text-align: center;"}
dt\[[i]{style="color:blue;"}, [j]{style="color:red;"}, [by]{style="color:green;"}\]
:::
:::

#### Apply a function to multiple columns

::: columns
::: {.column .fragment width="40%"}
-   Let us round the numeric columns to integers...
:::

::: {.column .fragment width="60%"}
```{r }
#| eval:  true
#| warning: false
numeric_cols <- names(iris_dt)[sapply(iris_dt, is.numeric)]
iris_dt[, lapply(
    .SD, as.integer
), .SDcols = numeric_cols] |> head(2)
```
:::
:::

#### Define multiple columns at once

::: columns
::: {.column .fragment width="40%"}
-   ... and store them in columns with the same name, but with a `_int` suffix.
:::

::: {.column .fragment width="60%"}
```{r }
#| eval: true
#| warning: false
new_cols <- paste0(numeric_cols, "_int")
iris_dt[, (new_cols) := lapply(
    .SD, as.integer
), .SDcols = numeric_cols]; head(iris_dt, n=2)
```
:::
:::

## Summary and advanced topics

::: nonincremental
-   `data.table` is a powerful package for data manipulation.
-   quick to write and quick to run BUT not the easiest to read.

Advanced topics:

-   Definitely print out a [cheatsheet](https://rstudio.github.io/cheatsheets/datatable.pdf) if you want to start using it.
-   [data.table function reference](https://rdatatable.gitlab.io/data.table/reference/index.html) for additional wrangling utilities.
-   [Vignettes](https://rdatatable.gitlab.io/data.table/articles/datatable-intro.html) for more advanced topics.
:::

::: {footer}
:::

## Profiling

-   Identify (and hopefully fix!) bottlenecks in your code.
-   The [`profvis`](https://rstudio.github.io/profvis/) package is a good package to use for this purpose.

![](../figures/profiling.webp){.fragment height="350" fig-align="center"}

## Profiling Example: Column Means

```{r prof}
#| eval: true
#| output-location: slide
library(profvis)
library(data.table)
n <- 4e5
cols <- 150
data <- as.data.frame(x = matrix(rnorm(n * cols, mean = 5), ncol = cols))
data <- cbind(id = paste0("g", seq_len(n)), data)
dataDF <- as.data.table(data)
numeric_vars <- setdiff(names(data), "id")

profvis({
  means <- apply(data[, names(data) != "id"], 2, mean)
  means <- colMeans(data[, names(data) != "id"])
  means <- lapply(data[, names(data) != "id"], mean)
  means <- vapply(data[, names(data) != "id"], mean, numeric(1))
  means <- matrixStats::colMeans2(as.matrix(data[, names(data) != "id"]))
  means <- dataDF[, lapply(.SD, mean), .SDcols = numeric_vars]
})
```

## Good coding practice: Reproducibility & Generalisability

Why are code reproducibility & generalisability important?

-   ‚úÖ Transparency & Verification
-   ü§ù Collaboration & Longevity
-   üîç Quicker detection of errors

## Reproducibility

-   Main idea: Be able to reproduce results to ensure they are valid.
-   Common practices:
    -   Setting the seed
    -   Importing all necessary packages
    -   Documenting R environment ([`sessionInfo()`](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/sessionInfo))

::: columns
::: {.column .fragment width="33%"}
```{r}
#| filename: "bad way"
#| error: false
x <- rnorm(1)
dtruncnorm(x, -5, 5, 0, 1)
```
:::

::: {.column .fragment width="33%"}
```{r}
#| filename: "still bad..."
#| error: false
set.seed(1234)
x <- rnorm(1)
dtruncnorm(x, -5, 5, 0, 1)
```
:::

::: {.column .fragment width="33%"}
```{r}
#| filename: "there we go!"
library(truncnorm)
set.seed(1234)
x <- rnorm(1)
dtruncnorm(x, -5, 5, 0, 1)
```
:::
:::

## Generalisability

-   Code should be "generalisable" meaning that anyone else can refer to it and use it on their own data.
-   Common practices:
    -   ‚öôÔ∏è Write functions for operations you use frequently
    -   üí¨ Document your code (add comments)
    -   ‚ùì Add basic checks (testing)
    -   ‚úîÔ∏è‚ùå Test your code on different data sets

## Generalisability: Example {.smaller}

-   **Task:** Create a function `kmeans_recip` that does the following:
    -   Takes a data set as input.
    -   Computes reciprocals of variables (i.e. for each value $x$ it computes $1/x$).
    -   Performs K-Means clustering (function `kmeans`) on the resulting data set.
    -   Returns the cluster assignment for the first 20 observations.
-   This function will be used on the `iris` data set (with K=3 clusters).

## Generalisability: Bad example

::: fragment
```{r badex_gen}
#| filename: "don't even bother..."
#| eval: true
#| error: false
kmeans_recip <- function(){
  for (i in c(1:4)){
    iris[, i] <- 1/iris[, i]
  }
  kmeans_res <- kmeans(iris[, c(1:4)], centers = 3)
  return(kmeans_res$cluster)
}
kmeans_recip()[1:20]
```
:::

## Generalisability: OK example

-   The previous example works but it's really not generalisable...
-   Obvious things that need improvement:
    -   Hardcoded values (first 4 columns are numeric in `iris`)
    -   Data set should be an input argument

::: fragment
```{r okex_gen}
#| filename: "it's getting better"
#| eval: true
#| error: false
kmeans_recip <- function(data, cont_cols){
  for (i in cont_cols){
    data[, i] <- 1/data[, i]
  }
  kmeans_res <- kmeans(data[, cont_cols], centers = 3)
  return(kmeans_res$cluster)
}
kmeans_recip(data = iris, cont_cols = c(1:4))[1:20]
```
:::

## Generalisability: Good example {.smaller}

-   We can still do better! More things to consider:
    -   Division by 0 is not allowed
    -   Determine numerical variables automatically
    -   Ensure there exists at least one continuous variable
    -   Add some comments

::: fragment
```{r goodex_gen}
#| filename: "that's looking good"
#| eval: true
#| error: false
kmeans_recip <- function(data){
  # Obtain numerical variables
  cont_cols <- which(sapply(data, is.numeric))
  # Check there is at least 1 numerical variable
  if (length(cont_cols)==0) stop('No numerical variables!')
  for (i in cont_cols){
    # Check if numerical variable takes 0 value
    ifelse(any(data[, i] == 0),
           stop('Division by 0 not allowed!'),
           data[, i] <- 1/data[, i])
  }
  # Apply K-Means clustering
  kmeans_res <- kmeans(data[, cont_cols], centers = 3)
  return(kmeans_res$cluster)
}
kmeans_recip(data = iris)[1:20]
```
:::

## Generalisability: Can we generalise?

-   Now we can also check if this works on the `diamonds` data set from the `ggplot2` package.

::: fragment
```{r diamonds}
#| filename: "seems like it works!"
#| eval: true
#| error: true
library(ggplot2)
kmeans_recip(data = diamonds)[1:20]
```
:::

## Debugging

-   üêõ Debugging is the process of finding and fixing errors in your code.
-   ü§¨ Generally annoying but can be made much easier with a few simple steps!

![](../figures/debugging.png){.fragment height="300" fig-align="center"}

## Debugging made easy

-   Common practices to debug your code more easily include:
    -   üìñ Read error messages carefully
    -   üñ®Ô∏è Use print messages (`cat()`, `print()`, `message()` etc.)
    -   üíæ Save objects that may be causing the error (to be able to reproduce it)
    -   üìë A bit more "advanced" options are `traceback()`, `browser()`, `debug()` [(more details here)](https://adv-r.hadley.nz/debugging.html)
    -   üíª [Don't forget:]{.underline} Google, Stack Overflow, ChatGPT etc. are your friends

## Error Handling

-   üò∞ Sometimes errors cannot be avoided...
-   üéâ Good news is we can handle them!
-   üíä Error handling is the process of responding to and recovering from error conditions.

![](../figures/errorhandling.webp){.fragment height="300" fig-align="center"}

## Error Handling: the `tryCatch()` syntax

-   [`tryCatch()`](https://www.r-bloggers.com/2020/10/basic-error-handing-in-r-with-trycatch/) is the function to use for error handling in R.

::: fragment
```{r trycatch_syntax}
#| filename: "basic tryCatch syntax"
#| eval: false
result <- tryCatch({
  expr
  },
  warning = function(w){
    warning-handler-code
    },
  error = function(e){
    error-handler-code
    },
  finally = {
    cleanup-code
  }
)
```
:::

## Error Handling: basic example

::: fragment
```{r tryCatch_ex}
#| filename: "tryCatch example"
#| eval: true
safe_log <- function(x){
  result <- tryCatch({
    log(x) # Attempt to calculate the logarithm
  },
  warning = function(w){
    message("A warning occurred: ", w) # Handle warnings
    NULL # Return NULL if a warning occurs
  },
  error = function(e){
    message("An error occurred: ", e) # Handle the error
    NA  # Return NA if an error occurs
  },
  finally = {
    # This block executes no matter what
    message("Logarithm attempt completed.")
  })
  return(result)
}

```
:::

## Error Handling: basic example

::: fragment
```{r tryCatch_res}
#| filename: "tryCatch works!"
#| eval: true
#| echo: true
#| warning: true
#| error: true
print(safe_log(2024))
print(safe_log(-8))
print(safe_log("zero"))

```
:::

::: notes
{background-iframe="hello-matrix/index.html"} let us add this with the hex of data.table at the end.
:::
